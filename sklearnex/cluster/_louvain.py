# ===============================================================================
# Copyright 2024 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ===============================================================================

import numbers
from numbers import Integral, Real

import numpy as np
from scipy import sparse as sp
from sklearn.base import BaseEstimator, ClusterMixin
from sklearn.metrics.pairwise import KERNEL_PARAMS, pairwise_kernels
from sklearn.neighbors import kneighbors_graph
from sklearn.utils._param_validation import Interval, StrOptions

from daal4py.sklearn._n_jobs_support import control_n_jobs
from onedal.cluster import Louvain as onedal_Louvain

from .._device_offload import dispatch
from ..neighbors import NearestNeighbors
from .._utils import PatchingConditionsChain


@control_n_jobs(decorated_methods=["fit"])
class Louvain(ClusterMixin, BaseEstimator):
    """Cluster data using the Louvain network clustering algorithm.

    The Louvain algorithm is useful in circumstances where the affinity
    matrix of the data is sparse, providing operational runtime of 
    approximately :math:`O(n * log(n))` for n samples. In cases where
    dense inputs are provided, a more-sparse representation is first
    generated.

    Output of the algorithm will yield a unique label generated by the
    greedy optimization of the graph modularity[1]_. The number of 
    clusters is determined, not specified.

    When calling ``fit``, an affinity matrix is constructed using either
    a kernel function such the Gaussian (aka RBF) kernel with Euclidean
    distance ``d(X, X)``::

            np.exp(-gamma * d(X,X) ** 2)

    or a k-nearest neighbors connectivity matrix.

    Alternatively, a user-provided affinity matrix can be specified by
    setting ``affinity='precomputed'``.


    Parameters
    ----------
    resolution: float, default=1.0


    tol: float, default=1e-4
        Tolerance for stopping criteria.

    max_iter : int, default=10
        Maximum number of iterations taken for Louvain algorithm convergence.

    gamma : float, default=1.0
        Kernel coefficient for rbf, poly, sigmoid, laplacian and chi2 kernels.
        Ignored for ``affinity='nearest_neighbors'``, ``affinity='precomputed'``
        or ``affinity='precomputed_nearest_neighbors'``.

    affinity : str or callable, default='rbf'
        How to construct the affinity matrix.
         - 'nearest_neighbors': construct the affinity matrix by computing a
           graph of nearest neighbors.
         - 'rbf': construct the affinity matrix using a radial basis function
           (RBF) kernel.
         - 'precomputed': interpret ``X`` as a precomputed affinity matrix,
           where larger values indicate greater similarity between instances.
         - 'precomputed_nearest_neighbors': interpret ``X`` as a sparse graph
           of precomputed distances, and construct a binary affinity matrix
           from the ``n_neighbors`` nearest neighbors of each instance.
         - one of the kernels supported by
           :func:`~sklearn.metrics.pairwise.pairwise_kernels`.

        Only kernels that produce similarity scores (non-negative values that
        increase with similarity) should be used. This property is not checked
        by the clustering algorithm.

    n_neighbors : int, default=10
        Number of neighbors to use when constructing the affinity matrix using
        the nearest neighbors method. Ignored for ``affinity='rbf'``.

    degree : float, default=3
        Degree of the polynomial kernel. Ignored by other kernels.

    coef0 : float, default=1
        Zero coefficient for polynomial and sigmoid kernels.
        Ignored by other kernels.

    kernel_params : dict of str to any, default=None
        Parameters (keyword arguments) and values for kernel passed as
        callable object. Ignored by other kernels.

    n_jobs : int, default=None
        The number of parallel jobs to run when `affinity='nearest_neighbors'`
        or `affinity='precomputed_nearest_neighbors'`. The neighbors search
        will be done in parallel.
        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.
        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`
        for more details.

    verbose : bool, default=False
        Verbosity mode.

    Attributes
    ----------
    affinity_matrix_ : array-like of shape (n_samples, n_samples)
        Affinity matrix used for clustering. Available only after calling
        ``fit``.

    community_count_ : int
        Number of communities generated during :term:`fit`.

    modularity_ : float
        The network modularity seen during :term:`fit`.

    labels_ : ndarray of shape (n_samples,)
        Labels of each point

    n_features_in_ : int
        Number of features seen during :term:`fit`.

        .. versionadded:: 0.24

    feature_names_in_ : ndarray of shape (`n_features_in_`,)
        Names of features seen during :term:`fit`. Defined only when `X`
        has feature names that are all strings.

        .. versionadded:: 1.0

    See Also
    --------
    sklearn.cluster.KMeans : K-Means clustering.
    sklearn.cluster.DBSCAN : Density-Based Spatial Clustering of
        Applications with Noise.

    Notes
    -----
    A distance matrix for which 0 indicates identical elements and high values
    indicate very dissimilar elements can be transformed into an affinity /
    similarity matrix that is well-suited for the algorithm by
    applying the Gaussian (aka RBF, heat) kernel::

        np.exp(- dist_matrix ** 2 / (2. * delta ** 2))

    where ``delta`` is a free parameter representing the width of the Gaussian
    kernel.

    An alternative is to take a symmetric version of the k-nearest neighbors
    connectivity matrix of the points.

    References
    ----------
    .. [1] :doi:`Fast unfolding of communities in large networks, 2008
           Blondel, Vincent D; Guillaume, Jean-Loup; Lambiotte, Renaud; Lefebvre, Etienne
           <10.1088/1742-5468/2008/10/P10008>`

    Examples
    --------
    >>> from sklearnex.cluster import Louvain
    >>> import numpy as np
    >>> X = np.array([[1, 1], [2, 1], [1, 0],
    ...               [4, 7], [3, 5], [3, 6]])
    >>> clustering = Louvain(n_clusters=2, random_state=0).fit(X)
    >>> clustering.labels_
    array([1, 1, 1, 0, 0, 0])
    >>> clustering
    Louvain(n_clusters=2, random_state=0)
    """

    if sklearn_check_version("1.2"):
        _parameter_constraints: dict = {
            "resolution": [Interval(Real, 0.0, None, closed="left")],
            "tol": [Interval(Real, 0, None, closed="left")],
            "max_iter": [Interval(Integral, 0, None, closed="left")],
            "gamma": [Interval(Real, 0, None, closed="left")],
            "affinity": [
                callable,
                StrOptions(
                    set(KERNEL_PARAMS)
                    | {"nearest_neighbors", "precomputed", "precomputed_nearest_neighbors"}
                ),
            ],
            "n_neighbors": [Interval(Integral, 1, None, closed="left")],
            "degree": [Interval(Real, 0, None, closed="left")],
            "coef0": [Interval(Real, None, None, closed="neither")],
            "kernel_params": [dict, None],
            "n_jobs": [Integral, None],
            "verbose": ["verbose"],
        }

    def __init__(
        self,
        resolution=1.0,
        *,
        tol=1e-4,
        max_iter=10,
        gamma=1.0,
        affinity="rbf",
        n_neighbors=10,
        degree=3,
        coef0=1,
        kernel_params=None,
        n_jobs=None,
        verbose=False,
    ):
        self.resolution = resolution
        self.tol = tol
        self.max_iter = max_iter
        self.gamma = gamma
        self.affinity = affinity
        self.n_neighbors = n_neighbors
        self.degree = degree
        self.coef0 = coef0
        self.kernel_params = kernel_params
        self.n_jobs = n_jobs
        self.verbose = verbose

    def fit(self, X, y=None):
        dispatch(
            self,
            "fit",
            {
                "onedal": self.__class__._onedal_fit,
                "sklearn": None,
            },
            X,
            y,
        )
        return self

    def _onedal_fit(self, X, y, queue=None):
        if sklearn_check_version("1.0"):
            X = self._validate_data(X, force_all_finite=False)

        onedal_params = {
            "eps": self.eps,
            "min_samples": self.min_samples,
            "metric": self.metric,
            "metric_params": self.metric_params,
            "algorithm": self.algorithm,
            "leaf_size": self.leaf_size,
            "p": self.p,
            "n_jobs": self.n_jobs,
        }
        self._onedal_estimator = self._onedal_dbscan(**onedal_params)

        self._onedal_estimator.fit(X, y=y, sample_weight=sample_weight, queue=queue)
        self._save_attributes()

    def _onedal_supported(self, method_name, *data):
        class_name = self.__class__.__name__
        patching_status = PatchingConditionsChain(
            f"sklearn.cluster.{class_name}.{method_name}"
        )
        self._validate_params()
        return patching_status

    _onedal_cpu_supported = _onedal_supported
    _onedal_gpu_supported = _onedal_supported

    def fit(self, X, y=None, sample_weight=None):
        if sklearn_check_version("1.2"):
            self._validate_params()
        elif sklearn_check_version("1.1"):
            check_scalar(
                self.eps,
                "eps",
                target_type=numbers.Real,
                min_val=0.0,
                include_boundaries="neither",
            )
            check_scalar(
                self.min_samples,
                "min_samples",
                target_type=numbers.Integral,
                min_val=1,
                include_boundaries="left",
            )
            check_scalar(
                self.leaf_size,
                "leaf_size",
                target_type=numbers.Integral,
                min_val=1,
                include_boundaries="left",
            )
            if self.p is not None:
                check_scalar(
                    self.p,
                    "p",
                    target_type=numbers.Real,
                    min_val=0.0,
                    include_boundaries="left",
                )
            if self.n_jobs is not None:
                check_scalar(self.n_jobs, "n_jobs", target_type=numbers.Integral)
        else:
            if self.eps <= 0.0:
                raise ValueError(f"eps == {self.eps}, must be > 0.0.")

        if sample_weight is not None:
            sample_weight = _check_sample_weight(sample_weight, X)
        dispatch(
            self,
            "fit",
            {
                "onedal": self.__class__._onedal_fit,
                "sklearn": sklearn_DBSCAN.fit,
            },
            X,
            y,
            sample_weight,
        )

        return self

    fit.__doc__ = sklearn_DBSCAN.fit.__doc__
